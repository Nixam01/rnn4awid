{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3643dae755904405",
   "metadata": {},
   "source": [
    "- Julia version: 1.10\n",
    "- Author: Marcin Latawiec (311031)\n",
    "- Date: 2024-06-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2619a88-0ac7-48a8-95ed-8e721bac7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module AccuracyModule.\n",
      "WARNING: replacing module AccuracyModule.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.GradientOptimizersModule"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/Graph.jl\")\n",
    "include(\"../src/DataModule.jl\")\n",
    "include(\"../src/UtilsModule.jl\")\n",
    "include(\"../src/AccuracyModule.jl\")\n",
    "include(\"../src/GradientOptimizersModule.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96be8f98-e62a-44e3-81d5-68bac36bdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using .DataModule, .UtilsModule, .AccuracyModule\n",
    "using Random, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc896d89-6745-4797-8196-8850883ae152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_data(batch_size)\n",
    "    println(\"Loading train data...\")\n",
    "    train_x, train_y = DataModule.preprocess(:train; one_hot = true)\n",
    "\n",
    "    train_x_batched = DataModule.batch(train_x, batch_size)\n",
    "    train_y_batched = DataModule.batch(train_y, batch_size)\n",
    "\n",
    "    println(\"Loading test data...\")\n",
    "    test_x, test_y = DataModule.preprocess(:test; one_hot = true)\n",
    "    return train_x, train_y, train_x_batched, train_y_batched, test_x, test_y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28802dce-96b0-4476-bc1c-ac93466447c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_weights!(graph::Vector, optimizer::GradientOptimizersModule.GradientOptimizer)\n",
    "    for node in graph\n",
    "        if isa(node, Variable)\n",
    "            if node.gradient != nothing\n",
    "                node.output .-= optimizer(node.gradient)\n",
    "                node.gradient .= 0\n",
    "            elseif node.gradient == nothing\n",
    "                node.output = nothing\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665445e0-dde8-47b0-aeba-35aff77c8ab6",
   "metadata": {},
   "source": [
    "Parametryzowana architektura sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e065772-5025-4035-8d9e-bad67cf0371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main(batch_size, epochs, optimizer)\n",
    "    train_x, train_y, train_x_batched, train_y_batched, test_x, test_y = load_data(batch_size)\n",
    "\n",
    "    x = Variable([0.], name=\"x\")\n",
    "\n",
    "    wd = Variable(UtilsModule.glorot_uniform(10, 64))\n",
    "    bd = Variable(UtilsModule.glorot_uniform(10, ))\n",
    "    fd = Constant(UtilsModule.identity)\n",
    "    dfd = Constant(UtilsModule.identity_deriv)\n",
    "\n",
    "    wr = Variable(UtilsModule.glorot_uniform(64, 196))\n",
    "    br = Variable(UtilsModule.glorot_uniform(64, ))\n",
    "    hwr = Variable(UtilsModule.glorot_uniform(64, 64))\n",
    "    states = Variable(nothing, name = \"states\")\n",
    "    fr = Constant(tanh)\n",
    "    dfr = Constant(UtilsModule.tanh_deriv)\n",
    "\n",
    "    optimizer = GradientOptimizersModule.Descent(15e-3)\n",
    "\n",
    "    r = rnn_layer(x, wr, br, hwr, states, fr, dfr)\n",
    "    d = dense_layer(r, wd, bd, fd, dfd)\n",
    "    graph = topological_sort(d)\n",
    "\n",
    "\n",
    "    batch_loss = Float64[]\n",
    "    batch_acc = Float64[]\n",
    "    println(\"Training\")\n",
    "    for epoch in 1:epochs\n",
    "        batches = randperm(size(train_x_batched, 1))\n",
    "        @time for batch in batches\n",
    "            states.output = nothing\n",
    "            x.output = train_x_batched[batch][  1:196,:]\n",
    "            forward!(graph)\n",
    "\n",
    "            x.output = train_x_batched[batch][197:392,:]\n",
    "            forward!(graph)\n",
    "\n",
    "            x.output = train_x_batched[batch][393:588,:]\n",
    "            forward!(graph)\n",
    "\n",
    "            x.output = train_x_batched[batch][589:end,:]\n",
    "            result = forward!(graph)\n",
    "\n",
    "            loss = AccuracyModule.loss(result, train_y_batched[batch])\n",
    "            acc = AccuracyModule.accuracy(result, train_y_batched[batch])\n",
    "            push!(batch_loss, loss)\n",
    "            push!(batch_acc, acc)\n",
    "            \n",
    "            gradient = AccuracyModule.gradient(result, train_y_batched[batch]) ./ batch_size\n",
    "            backward!(graph, seed=gradient)\n",
    "            update_weights!(graph, optimizer)\n",
    "        end\n",
    "        states.output = nothing\n",
    "        test_graph = topological_sort(d)\n",
    "\n",
    "        x.output = test_x[  1:196,:]\n",
    "        forward!(test_graph)\n",
    "\n",
    "        x.output = test_x[197:392,:]\n",
    "        forward!(test_graph)\n",
    "\n",
    "        x.output = test_x[393:588,:]\n",
    "        forward!(test_graph)\n",
    "\n",
    "        x.output = test_x[589:end,:]\n",
    "        result = forward!(test_graph)\n",
    "\n",
    "        loss = AccuracyModule.loss(result, test_y)\n",
    "        acc = AccuracyModule.accuracy(result, test_y)\n",
    "\n",
    "        @show epoch loss acc\n",
    "    end\n",
    "    return batch_loss, batch_acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71007e34-648b-44dc-b56b-b5c86ad83ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Loading test data...\n",
      "Training\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching Vector{Float64}(::Matrix{Float32})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  Array{T, N}(::AbstractArray{S, N}) where {T, N, S}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4marray.jl:673\u001b[24m\u001b[39m\n\u001b[0m  Array{T, N}(\u001b[91m::Missing\u001b[39m, Any...) where {T, N}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mbaseext.jl:43\u001b[24m\u001b[39m\n\u001b[0m  Vector{T}(\u001b[91m::UndefInitializer\u001b[39m, \u001b[91m::Tuple{Int64}\u001b[39m) where T\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m\u001b[4mboot.jl:486\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Vector{Float64}(::Matrix{Float32})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  Array{T, N}(::AbstractArray{S, N}) where {T, N, S}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4marray.jl:673\u001b[24m\u001b[39m\n\u001b[0m  Array{T, N}(\u001b[91m::Missing\u001b[39m, Any...) where {T, N}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mbaseext.jl:43\u001b[24m\u001b[39m\n\u001b[0m  Vector{T}(\u001b[91m::UndefInitializer\u001b[39m, \u001b[91m::Tuple{Int64}\u001b[39m) where T\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m\u001b[4mboot.jl:486\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] convert(::Type{Vector{Float64}}, a::Matrix{Float32})",
      "   @ Base .\\array.jl:665",
      " [2] setproperty!(x::Variable{Vector{Float64}}, f::Symbol, v::Matrix{Float32})",
      "   @ Base .\\Base.jl:40",
      " [3] macro expansion",
      "   @ .\\In[7]:32 [inlined]",
      " [4] macro expansion",
      "   @ .\\timing.jl:279 [inlined]",
      " [5] main(batch_size::Int64, epochs::Int64, optimizer::Main.GradientOptimizersModule.Descent)",
      "   @ Main .\\In[7]:30",
      " [6] top-level scope",
      "   @ In[8]:1"
     ]
    }
   ],
   "source": [
    "batch_loss, batch_acc = main(100, 5, GradientOptimizersModule.Descent(15e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529682f0-a08d-4771-bc33-53e40d5acd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
